################################################################################
# MASTER PARAMETER FILE FOR KLUSTA2
# xs-ldas5-klusta2 will replace "dummy" with:
# 	- experiment name
#	- probe file name (probe file also generated by xs-ldas5-klusta2)
#	- data file name
#	- detect_spikes direction, negative or positive
# in the future, should also define sample_rate, n_channels and dtype
################################################################################
experiment_name='dummy'
prb_file='dummy'  # or the path to your PRB file

traces = dict(
    raw_data_files=['dummy'],  # path to your .dat file(s)
    sample_rate=19531.25,  # sampling rate in Hz
    n_channels=16,  # number of channels in the .dat files
    dtype='int16',  # the data type used in the .dat files
)

# Parameters for the spike detection process.
spikedetekt = dict(
    filter_low=500.,
    filter_high_factor= 0.95 * .5,  # will be multiplied by the sample rate
    filter_butter_order=3,
    # Data chunks.
    chunk_size_seconds=1.,
    chunk_overlap_seconds=.015,
    # Threshold.
    n_excerpts=50,
    excerpt_size_seconds=1.,
    use_single_threshold=True,
    threshold_strong_std_factor=4.5,
    threshold_weak_std_factor=2.,
    detect_spikes='dummy',
    # Connected components.
    connected_component_join_size= 1,
    # Spike extractions.
    extract_s_before=8,
    extract_s_after=24,
    #weight_power=2,
    # Features.
    n_features_per_channel=3,
    pca_n_waveforms_max=10000,
)

# Parameters for the automatic clustering process.
# to make KK detect more clusters, use Akaike Information Critierion (AIC) instead: 
# 	penalty_k = 1    (multiples of AIC - results in more clusters)
# 	penalty_k_log_n = 0  (multiples of BIC)
klustakwik2 = dict(
     prior_point=1,
     mua_point=2,
     noise_point=1,
     points_for_cluster_mask=100,
#     penalty_k=0.0,
#     penalty_k_log_n=1.0,
     penalty_k=1.0,
     penalty_k_log_n=0.0,
     max_iterations=500,
     num_starting_clusters=25,
     max_possible_clusters=100,
     use_noise_cluster=True,
     use_mua_cluster=True,
     num_changed_threshold=0.05,
     full_step_every=1,
     split_first=20,
     split_every=40,
     dist_thresh= 'log(10000.0)',
     max_quick_step_candidates=100000000, # this uses around 760 MB RAM
     max_quick_step_candidates_fraction=0.4,
     always_split_bimodal=False,
     subset_break_fraction=0.01,
     break_fraction=0.0,
     fast_split=False,
     max_split_iterations=None,
     consider_cluster_deletion=True,
     num_cpus=2,
)
